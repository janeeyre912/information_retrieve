* Project Source code and data file *
*************************************
testData--downloaded html files
   concordia_crawler.py
   extract_html_text.py

*   How to scrawle the pages        *
*************************************
Terminal: scrapy runspider concordia_crawler.py
run concordia_crawler.py and will start to crawle and download html files to testData folder.

* cluster document collection and derive cluster sentiment scores *
*******************************************************************
execute extract_html_text.py 
